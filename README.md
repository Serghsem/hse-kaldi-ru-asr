# Russian Speech Recognition with Kaldi DNN using voxforge_ru dataset
## Instructions

1. Optional: for a large boost in performance of the DNN training process, install the CUDA toolkit (https://developer.nvidia.com/cuda-toolkit) if proper hardware (CUDA GPU) is available. Without it the DNNs can still be run on a CPU using --skip-cuda-check but it will significantly slow down the training process.
2. Install the Kaldi toolkit (follow instructions at http://kaldi-asr.org/doc/install.html) and the voxforge_ru (git clone https://github.com/freerussianasr/recipes) recipe for Kaldi. 
3. Add local/nnet2/run\_dnn.sh file (nnet2) to the voxforge\_ru folder and replace path.sh with the one included in this repository. Note that at the time of writing this, path.sh included in voxforge\_ru uses outdated paths for some of Kaldi executables (e. g. arpa2fst - kaldi/src/lm -> kaldi/src/lmbin, cuda-compiled - kaldi/src/nnet2bin), so modifying path.sh is required even while not running nnet2. Set paths for dataset storing (DATA\_ROOT) and Kaldi distribution (KALDI\_ROOT).
4. Run the getdata.sh script from voxforge_ru to download and extract audio dataset.
5. Voxforge\_ru scripts rely on scripts from the voxforge example included in the Kaldi distribution, create symbolic links steps to kaldi/egs/voxforge/s5/steps and utils to kaldi/egs/voxforge/s5/utils in the voxforge_ru folder for the scripts to function properly.
6. run.sh script requires the following to be installed: flac (sudo apt-get install flac), SRILM (run kaldi/tools/install\_srilm.sh), SEQUITUR (run kaldi/tools/extras/install\_sequitur.sh).
7. Configure (e. g. set number of parallel jobs) and run the run.sh script.
8. To run the first neural network (nnet1) run local/nnet/run\_dnn.sh from the voxforge\_ru directory. To run the second neural network (nnet2) run local/nnet2/run\_dnn.sh from the voxforge\_ru directory. Note that in both cases GMM is assumed to be already generated by the run.sh script.

It's possible to retrain a DNN from a certain stage or resume its training from it by running the script with --stage N.

## DNN summary

The first DNN uses the nnet Kaldi DNN implementation and can be run only on a single GPU. It is included in the voxforge_ru recipe. It uses MFCC-LDA-MLLT-SAT-fMMLR features, runs RBM pretraining followed by cross-entropy training and then sMBR training.

The second DNN uses the nnet2 Kaldi DNN implementation, can be run on multiple GPUs. It was modified from the Wall Street Journal example included in the Kaldi distribution to be run on the voxforge_ru dataset. It uses unadapted MFCC features and employs combinations of time-warping and VTLN warping in order to generate more train data.

## Computational results

The WER statistic is used to evaluate training results of both neural networks. Word Error Rate = (I + D + S) / N, where I - number of insertions, D - number of deletions, S - number of substitutions required to get from the correct transcript to the predicted one, N - number of words in the correct transcript.

#### nnet1 (on different training stages)

dnn5b\_pretrain-dbn_dnn (after cross-entropy training)
%WER 11.96 \[ 413 / 3454, 111 ins, 98 del, 204 sub \]
dnn5b\_pretrain-dbn\_dnn\_smbr (after 1 iteration of sMBR training)
%WER 11.46 \[ 396 / 3454, 118 ins, 77 del, 201 sub \]
dnn5b\_pretrain-dbn\_dnn\_smbr\_i1lats (after re-generating lattices and more iterations of sMBR)
%WER 11.23 \[ 388 / 3454, 113 ins, 69 del, 206 sub \]

#### nnet2

Still training (to be updated)
